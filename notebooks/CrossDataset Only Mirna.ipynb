{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":36483,"status":"ok","timestamp":1743620010902,"user":{"displayName":"Rosa","userId":"16580809559782772792"},"user_tz":-120},"id":"jHvNFeh4D-IW","outputId":"69a3f4d4-771e-4992-cc98-4a82c272280b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/My Drive/Big data/Fold_esperimenti\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import os\n","os.chdir('/content/drive/My Drive/Big data/Fold_esperimenti')\n","\n","!pwd\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"markdown","metadata":{"id":"XqqTd2d3bK9W"},"source":["## Preprocessing dataset\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hNTfswD4aUcK"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","def process_dataframe(df: pd.DataFrame):\n","\n","  # Calculate the missing rate for each column\n","  missing_rate = df.isnull().mean()\n","\n","  df = df.drop([ 'Unnamed: 0', 'country', 'age', 'sex', 'apoe4'], axis=1)\n","\n","  df['disease'] = df['disease'].replace({'AD': 0, 'NC': 1, 'MCI': 2})\n","\n","\n","  # Sort in discending order\n","  missing_rate_sorted = missing_rate.sort_values(ascending= False)\n","\n","  # Filter columns that have a missing rate <= 5 %\n","  threshold = 0.05\n","  df = df.loc[:, missing_rate <= threshold]\n","\n","  # Substitute null with zero\n","  df.fillna(0, inplace=True)\n","\n","\n","  return df"]},{"cell_type":"markdown","metadata":{"id":"ZrZqb7QipZV4"},"source":["# AUTO ENCODERS"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"39LeOjGeqqjm"},"outputs":[],"source":["import numpy as np\n","from tensorflow.keras.layers import Input, Dense, Dropout\n","from tensorflow.keras.models import Model\n","from tensorflow.keras import regularizers\n","\n","REG_COEFF = 0.03\n","DROPOUT_RATE = 0.6\n","\n","def generate_intermediate_feature(X_train, X_test,\n","                                  hidden_dim1=256,\n","                                  hidden_dim2=128,\n","                                  epochs=100,\n","                                  batch_size=256):\n","    \"\"\"\n","    Costruisce e addestra un autoencoder a due livelli (256 e 128) con\n","    regolarizzazione L2 e dropout, e restituisce le feature intermedie (128\n","    dimensioni) per train e test.\n","\n","    Parametri:\n","    -----------\n","    X_train : np.array\n","        Matrice delle feature di training, shape (num_samples, input_dim)\n","    X_test  : np.array\n","        Matrice delle feature di test, shape (num_samples, input_dim)\n","    hidden_dim1 : int\n","        Dimensione del primo livello nascosto (es. 256)\n","    hidden_dim2 : int\n","        Dimensione del secondo livello nascosto (es. 128, il bottleneck)\n","    epochs : int\n","        Numero di epoche per l'addestramento dell'autoencoder\n","    batch_size : int\n","        Dimensione del batch per l'addestramento\n","\n","    Restituisce:\n","    ------------\n","    features_intermediate_train : np.array\n","        Codifica di dimensione (num_samples_train, hidden_dim2)\n","    features_intermediate_test : np.array\n","        Codifica di dimensione (num_samples_test, hidden_dim2)\n","    \"\"\"\n","\n","    # Numero di feature in ingresso\n","    input_dim = X_train.shape[1]\n","\n","    # 1. Definizione dei layer\n","    input_layer = Input(shape=(input_dim,))\n","\n","    # Encoder\n","    encoded = Dense(hidden_dim1,\n","                    activation='relu',\n","                    kernel_regularizer=regularizers.l2(REG_COEFF)\n","                   )(input_layer)\n","    encoded = Dropout(DROPOUT_RATE)(encoded)\n","\n","    encoded = Dense(hidden_dim2,\n","                    activation='relu',\n","                    kernel_regularizer=regularizers.l2(REG_COEFF)\n","                   )(encoded)\n","    encoded = Dropout(DROPOUT_RATE)(encoded)\n","\n","    # Decoder\n","    decoded = Dense(hidden_dim1,\n","                    activation='relu',\n","                    kernel_regularizer=regularizers.l2(REG_COEFF)\n","                   )(encoded)\n","    decoded = Dropout(DROPOUT_RATE)(decoded)\n","\n","    # Output layer\n","    decoded = Dense(input_dim,\n","                    activation='sigmoid',\n","                    kernel_regularizer=regularizers.l2(REG_COEFF)\n","                   )(decoded)\n","\n","    # 2. Costruzione del modello Autoencoder\n","    autoencoder = Model(inputs=input_layer, outputs=decoded)\n","    autoencoder.compile(optimizer='adam', loss='mse')\n","\n","    # 3. Addestramento\n","    autoencoder.fit(X_train, X_train,\n","                    epochs=epochs,\n","                    batch_size=batch_size,\n","                    shuffle=True,\n","                    validation_data=(X_test, X_test))\n","\n","    # 4. Creazione del modello encoder\n","    # (l'output finale del nostro encoder è 'encoded' dopo il secondo Dropout)\n","    encoder = Model(inputs=input_layer, outputs=encoded)\n","\n","    # 5. Estrazione delle feature intermedie\n","    features_intermediate_train = encoder.predict(X_train)\n","    features_intermediate_test = encoder.predict(X_test)\n","\n","    # 6. Ritorno delle feature\n","    return features_intermediate_train, features_intermediate_test\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Ir6GJWl4Ef55"},"source":["# Random Forest Classifier\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zmAEzySrq6iL"},"outputs":[],"source":["from sklearn.ensemble import RandomForestClassifier\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import classification_report\n","\n","\n","def evaluate_model( X_train, X_test, y_train, y_test ) :\n","\n","\n","  # Random Forest Classifier\n","  rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n","  rf_classifier.fit(X_train, y_train)\n","\n","  y_pred = rf_classifier.predict(X_test)\n","\n","  # 'AD': 0, 'NC': 1, 'MCI': 2\n","  target_names = ['AD ', 'NC', 'MCI']\n","  print(classification_report(y_test, y_pred))\n","\n","  return classification_report(y_test, y_pred, output_dict=True)\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"inzPadloSSmQ"},"source":[]},{"cell_type":"markdown","metadata":{"id":"2G2esnpYnyrg"},"source":["# MLP Classifier"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Fk-ROOfwoduG"},"outputs":[],"source":["from sklearn.neural_network import MLPClassifier\n","def evaluate_model_mlp( X_train, X_test, y_train, y_test ) :\n","\n","\n","  # MLPClassifier  Classifier\n","  mlp_classifier = MLPClassifier(max_iter=100, random_state=42)\n","  mlp_classifier.fit(X_train, y_train)\n","\n","  y_pred = mlp_classifier.predict(X_test)\n","\n","  print(classification_report(y_test, y_pred))\n","  return classification_report(y_test, y_pred, output_dict=True)\n"]},{"cell_type":"markdown","metadata":{"id":"rRJ3m8yzsiqL"},"source":["# Preprocessing and Autoencoders"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JFIdtw7AAKEt"},"outputs":[],"source":["def checks_columns(df1: pd.DataFrame, df2: pd.DataFrame) -> bool:\n","    \"\"\"\n","    Verifica se due DataFrame hanno le stesse colonne, indipendentemente dall'ordine.\n","\n","    Parametri:\n","        df1 (pd.DataFrame): primo DataFrame\n","        df2 (pd.DataFrame): secondo DataFrame\n","\n","    Ritorna:\n","        bool: True se i DataFrame hanno le stesse colonne, False altrimenti.\n","    \"\"\"\n","    return set(df1.columns) == set(df2.columns)"]},{"cell_type":"code","source":["def remove_columns(df_train, df_test, label_col='disease'):\n","\n","    y_train = df_train['disease']\n","    y_test = df_test['disease']\n","\n","    df_train = df_train.drop('disease', axis=1)\n","    df_test = df_test.drop('disease', axis=1)\n","\n","    # Trova le colonne comuni tra df_train e df_test\n","    colonne_comuni = df_train.columns.intersection(df_test.columns)\n","\n","    # Mantieni solo le colonne comuni\n","    df_train_common = df_train[colonne_comuni]\n","    df_test_common = df_test[colonne_comuni]\n","\n","    return df_train_common, df_test_common, y_train, y_test\n"],"metadata":{"id":"MLUQR1xlbhVR"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uCV7bkwYxfvp"},"outputs":[],"source":["import pandas as pd\n","\n","def preprocess_data(df_train, df_test):\n","\n","\n","    features_mirna_train = process_dataframe(df_train)\n","    features_mirna_test = process_dataframe(df_test)\n","\n","    print(checks_columns(features_mirna_train, features_mirna_test))\n","\n","    features_final_train, features_final_test, y_train, y_test = remove_columns(features_mirna_train, features_mirna_test)\n","\n","    print(checks_columns(features_mirna_train, features_mirna_test))\n","\n","    features_final_train, features_final_test = generate_intermediate_feature(\n","        features_final_train, features_final_test)\n","\n","    return features_final_train, features_final_test, y_train, y_test\n","\n","def evaluate_models(features_train, features_test, y_train, y_test):\n","    report_dict_0 = evaluate_model(features_train, features_test, y_train, y_test)\n","    report_dict_1 = evaluate_model_mlp(features_train, features_test, y_train, y_test)\n","    return report_dict_0, report_dict_1\n"]},{"cell_type":"markdown","metadata":{"id":"tegxiv-GxIoJ"},"source":["# Cross-dataset Result\n","Train df_84_93_23.csv'\n","Test 'df_89.csv'\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JKrqJiNJzJGx","executionInfo":{"status":"ok","timestamp":1743620077180,"user_tz":-120,"elapsed":59520,"user":{"displayName":"Rosa","userId":"16580809559782772792"}},"outputId":"e59544eb-8473-43aa-9e73-c7d8cd5d13f2"},"outputs":[{"output_type":"stream","name":"stdout","text":["False\n","False\n","Epoch 1/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 124ms/step - loss: 2596.8057 - val_loss: 34.6579\n","Epoch 2/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 2505.9324 - val_loss: 28.1420\n","Epoch 3/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - loss: 2346.7766 - val_loss: 22.9202\n","Epoch 4/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 2305.8662 - val_loss: 18.7279\n","Epoch 5/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 2526.5103 - val_loss: 15.4605\n","Epoch 6/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 2542.4148 - val_loss: 13.0450\n","Epoch 7/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - loss: 2462.7422 - val_loss: 11.3253\n","Epoch 8/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - loss: 2419.5518 - val_loss: 10.1109\n","Epoch 9/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 2457.2634 - val_loss: 9.2378\n","Epoch 10/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 2735.9414 - val_loss: 8.5927\n","Epoch 11/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - loss: 2377.9009 - val_loss: 8.1020\n","Epoch 12/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - loss: 2106.7292 - val_loss: 7.7158\n","Epoch 13/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 2438.3777 - val_loss: 7.3983\n","Epoch 14/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 2598.0515 - val_loss: 7.1287\n","Epoch 15/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 2113.6409 - val_loss: 6.9008\n","Epoch 16/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - loss: 2568.6296 - val_loss: 6.6990\n","Epoch 17/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 2583.3750 - val_loss: 6.5254\n","Epoch 18/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 1857.9373 - val_loss: 6.3748\n","Epoch 19/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 2090.2065 - val_loss: 6.2409\n","Epoch 20/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 2470.3325 - val_loss: 6.1272\n","Epoch 21/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 2373.9985 - val_loss: 6.0247\n","Epoch 22/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 2280.3691 - val_loss: 5.9371\n","Epoch 23/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 2231.6626 - val_loss: 5.8594\n","Epoch 24/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 2575.9695 - val_loss: 5.7896\n","Epoch 25/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 2500.7903 - val_loss: 5.7331\n","Epoch 26/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 2517.8721 - val_loss: 5.6794\n","Epoch 27/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - loss: 2218.3657 - val_loss: 5.6365\n","Epoch 28/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - loss: 2231.9995 - val_loss: 5.5944\n","Epoch 29/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - loss: 2767.0371 - val_loss: 5.5603\n","Epoch 30/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 2136.8315 - val_loss: 5.5299\n","Epoch 31/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 2264.5364 - val_loss: 5.5026\n","Epoch 32/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - loss: 2674.0850 - val_loss: 5.4804\n","Epoch 33/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 2662.0115 - val_loss: 5.4606\n","Epoch 34/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 2711.0793 - val_loss: 5.4381\n","Epoch 35/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 2325.3889 - val_loss: 5.4263\n","Epoch 36/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - loss: 2405.1689 - val_loss: 5.4085\n","Epoch 37/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 2331.5728 - val_loss: 5.3951\n","Epoch 38/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - loss: 2680.8164 - val_loss: 5.3834\n","Epoch 39/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 2469.9990 - val_loss: 5.3725\n","Epoch 40/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - loss: 2853.0813 - val_loss: 5.3633\n","Epoch 41/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - loss: 2354.1760 - val_loss: 5.3569\n","Epoch 42/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 2275.0276 - val_loss: 5.3461\n","Epoch 43/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - loss: 2517.0386 - val_loss: 5.3408\n","Epoch 44/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - loss: 2825.0867 - val_loss: 5.3340\n","Epoch 45/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - loss: 2541.5669 - val_loss: 5.3261\n","Epoch 46/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 2250.8862 - val_loss: 5.3239\n","Epoch 47/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 2632.0605 - val_loss: 5.3167\n","Epoch 48/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 2334.5894 - val_loss: 5.3149\n","Epoch 49/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 2872.5442 - val_loss: 5.3086\n","Epoch 50/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 2446.6934 - val_loss: 5.3077\n","Epoch 51/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 2449.8394 - val_loss: 5.3019\n","Epoch 52/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 2332.3784 - val_loss: 5.2981\n","Epoch 53/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 2595.8801 - val_loss: 5.2969\n","Epoch 54/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 2126.6299 - val_loss: 5.2923\n","Epoch 55/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - loss: 2500.4897 - val_loss: 5.2907\n","Epoch 56/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 2268.7222 - val_loss: 5.2873\n","Epoch 57/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 2476.5688 - val_loss: 5.2885\n","Epoch 58/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - loss: 2478.3232 - val_loss: 5.2828\n","Epoch 59/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 2441.5525 - val_loss: 5.2834\n","Epoch 60/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 2549.5942 - val_loss: 5.2806\n","Epoch 61/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - loss: 2774.9270 - val_loss: 5.2792\n","Epoch 62/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 2368.6982 - val_loss: 5.2774\n","Epoch 63/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 2478.5247 - val_loss: 5.2757\n","Epoch 64/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 2216.5027 - val_loss: 5.2745\n","Epoch 65/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 2428.8047 - val_loss: 5.2782\n","Epoch 66/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 165ms/step - loss: 2666.7236 - val_loss: 5.2721\n","Epoch 67/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 187ms/step - loss: 2460.3892 - val_loss: 5.2731\n","Epoch 68/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 2052.9822 - val_loss: 5.2685\n","Epoch 69/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 170ms/step - loss: 2985.9602 - val_loss: 5.2732\n","Epoch 70/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - loss: 2646.8328 - val_loss: 5.2693\n","Epoch 71/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 2197.4614 - val_loss: 5.2709\n","Epoch 72/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 2104.8572 - val_loss: 5.2670\n","Epoch 73/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 2578.6606 - val_loss: 5.2711\n","Epoch 74/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 2074.3528 - val_loss: 5.2663\n","Epoch 75/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 2419.2700 - val_loss: 5.2712\n","Epoch 76/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 2738.4307 - val_loss: 5.2656\n","Epoch 77/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 2156.0623 - val_loss: 5.2718\n","Epoch 78/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 2514.0837 - val_loss: 5.2680\n","Epoch 79/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 2352.9111 - val_loss: 5.2714\n","Epoch 80/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 2165.1453 - val_loss: 5.2670\n","Epoch 81/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 2639.8745 - val_loss: 5.2707\n","Epoch 82/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - loss: 2268.5476 - val_loss: 5.2657\n","Epoch 83/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 2582.0078 - val_loss: 5.2727\n","Epoch 84/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 2407.9741 - val_loss: 5.2669\n","Epoch 85/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 2609.0996 - val_loss: 5.2712\n","Epoch 86/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 2233.9355 - val_loss: 5.2705\n","Epoch 87/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 2227.3467 - val_loss: 5.2704\n","Epoch 88/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 2337.4341 - val_loss: 5.2734\n","Epoch 89/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 2160.6814 - val_loss: 5.2731\n","Epoch 90/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - loss: 2362.0520 - val_loss: 5.2716\n","Epoch 91/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - loss: 2321.2300 - val_loss: 5.2746\n","Epoch 92/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - loss: 2025.7142 - val_loss: 5.2738\n","Epoch 93/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 2233.2366 - val_loss: 5.2747\n","Epoch 94/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 2523.6846 - val_loss: 5.2776\n","Epoch 95/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 2366.7048 - val_loss: 5.2757\n","Epoch 96/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 2744.3242 - val_loss: 5.2781\n","Epoch 97/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 2323.3052 - val_loss: 5.2783\n","Epoch 98/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 2701.1755 - val_loss: 5.2789\n","Epoch 99/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - loss: 2259.2437 - val_loss: 5.2823\n","Epoch 100/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 2314.2756 - val_loss: 5.2797\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n"]}],"source":["train_path = pd.read_csv('df_84_93_23.csv')\n","test_path = pd.read_csv('df_89.csv')\n","features_train, features_test, y_train, y_test = preprocess_data(train_path, test_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UDvGsvPmzaAU","executionInfo":{"status":"ok","timestamp":1743620079945,"user_tz":-120,"elapsed":2764,"user":{"displayName":"Rosa","userId":"16580809559782772792"}},"outputId":"faf8fe8b-5e5a-4d0c-e3d4-72b7846bed3f"},"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00        28\n","           1       0.26      1.00      0.41        21\n","           2       0.00      0.00      0.00        32\n","\n","    accuracy                           0.26        81\n","   macro avg       0.09      0.33      0.14        81\n","weighted avg       0.07      0.26      0.11        81\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00        28\n","           1       0.26      1.00      0.41        21\n","           2       0.00      0.00      0.00        32\n","\n","    accuracy                           0.26        81\n","   macro avg       0.09      0.33      0.14        81\n","weighted avg       0.07      0.26      0.11        81\n","\n"]}],"source":["report_dict_0, report_dict_1 = evaluate_models(features_train, features_test, y_train, y_test)"]},{"cell_type":"markdown","metadata":{"id":"eKFXCuVh16lA"},"source":["# Intra-dataset Results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zivaVOW8181g","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1743620098558,"user_tz":-120,"elapsed":18610,"user":{"displayName":"Rosa","userId":"16580809559782772792"}},"outputId":"29d4b3a6-79cf-49a5-e5dc-ca1aa1b3fbb7"},"outputs":[{"output_type":"stream","name":"stdout","text":["True\n","True\n","Epoch 1/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 42.9588 - val_loss: 40.9786\n","Epoch 2/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - loss: 40.9913 - val_loss: 39.1318\n","Epoch 3/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - loss: 39.1151 - val_loss: 37.3497\n","Epoch 4/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 37.3209 - val_loss: 35.6243\n","Epoch 5/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - loss: 35.5900 - val_loss: 33.9541\n","Epoch 6/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step - loss: 33.9335 - val_loss: 32.3367\n","Epoch 7/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 32.3195 - val_loss: 30.7700\n","Epoch 8/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 30.7764 - val_loss: 29.2530\n","Epoch 9/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 29.3007 - val_loss: 27.7859\n","Epoch 10/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 27.8554 - val_loss: 26.3713\n","Epoch 11/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 26.4794 - val_loss: 25.0121\n","Epoch 12/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 25.2169 - val_loss: 23.7159\n","Epoch 13/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 23.9298 - val_loss: 22.4928\n","Epoch 14/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 22.7827 - val_loss: 21.3535\n","Epoch 15/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 21.6485 - val_loss: 20.3027\n","Epoch 16/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 20.5817 - val_loss: 19.3375\n","Epoch 17/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - loss: 19.5651 - val_loss: 18.4482\n","Epoch 18/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 277ms/step - loss: 18.6355 - val_loss: 17.6226\n","Epoch 19/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 17.7824 - val_loss: 16.8488\n","Epoch 20/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 16.9536 - val_loss: 16.1180\n","Epoch 21/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 16.2138 - val_loss: 15.4256\n","Epoch 22/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 15.4826 - val_loss: 14.7679\n","Epoch 23/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 14.8287 - val_loss: 14.1434\n","Epoch 24/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 14.1733 - val_loss: 13.5502\n","Epoch 25/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 13.5718 - val_loss: 12.9877\n","Epoch 26/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - loss: 13.0053 - val_loss: 12.4554\n","Epoch 27/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 12.4825 - val_loss: 11.9535\n","Epoch 28/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - loss: 11.9754 - val_loss: 11.4810\n","Epoch 29/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 11.5258 - val_loss: 11.0385\n","Epoch 30/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 11.0538 - val_loss: 10.6236\n","Epoch 31/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 10.6583 - val_loss: 10.2361\n","Epoch 32/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 10.2606 - val_loss: 9.8747\n","Epoch 33/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - loss: 9.9106 - val_loss: 9.5384\n","Epoch 34/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 9.5710 - val_loss: 9.2253\n","Epoch 35/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 9.2664 - val_loss: 8.9342\n","Epoch 36/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 8.9741 - val_loss: 8.6630\n","Epoch 37/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 8.6833 - val_loss: 8.4103\n","Epoch 38/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - loss: 8.4501 - val_loss: 8.1750\n","Epoch 39/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 8.2175 - val_loss: 7.9560\n","Epoch 40/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 7.9895 - val_loss: 7.7521\n","Epoch 41/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 7.7525 - val_loss: 7.5616\n","Epoch 42/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 7.5869 - val_loss: 7.3839\n","Epoch 43/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 7.3921 - val_loss: 7.2174\n","Epoch 44/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 7.2449 - val_loss: 7.0614\n","Epoch 45/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - loss: 7.0846 - val_loss: 6.9152\n","Epoch 46/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 6.9245 - val_loss: 6.7772\n","Epoch 47/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 6.7788 - val_loss: 6.6468\n","Epoch 48/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - loss: 6.6568 - val_loss: 6.5237\n","Epoch 49/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 6.5383 - val_loss: 6.4074\n","Epoch 50/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 6.4074 - val_loss: 6.2970\n","Epoch 51/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - loss: 6.2970 - val_loss: 6.1919\n","Epoch 52/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step - loss: 6.1887 - val_loss: 6.0918\n","Epoch 53/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - loss: 6.1007 - val_loss: 5.9969\n","Epoch 54/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - loss: 5.9951 - val_loss: 5.9066\n","Epoch 55/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 277ms/step - loss: 5.8977 - val_loss: 5.8204\n","Epoch 56/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306ms/step - loss: 5.8368 - val_loss: 5.7388\n","Epoch 57/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 5.7460 - val_loss: 5.6611\n","Epoch 58/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - loss: 5.6876 - val_loss: 5.5872\n","Epoch 59/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - loss: 5.5972 - val_loss: 5.5168\n","Epoch 60/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 269ms/step - loss: 5.5109 - val_loss: 5.4493\n","Epoch 61/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - loss: 5.4489 - val_loss: 5.3845\n","Epoch 62/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 291ms/step - loss: 5.3952 - val_loss: 5.3224\n","Epoch 63/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - loss: 5.3361 - val_loss: 5.2628\n","Epoch 64/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 319ms/step - loss: 5.2715 - val_loss: 5.2056\n","Epoch 65/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 320ms/step - loss: 5.2084 - val_loss: 5.1504\n","Epoch 66/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 5.1532 - val_loss: 5.0970\n","Epoch 67/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262ms/step - loss: 5.0981 - val_loss: 5.0453\n","Epoch 68/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 5.0449 - val_loss: 4.9948\n","Epoch 69/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 5.0111 - val_loss: 4.9465\n","Epoch 70/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - loss: 4.9440 - val_loss: 4.8992\n","Epoch 71/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 4.9063 - val_loss: 4.8536\n","Epoch 72/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 4.8549 - val_loss: 4.8092\n","Epoch 73/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 4.7980 - val_loss: 4.7654\n","Epoch 74/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 4.7692 - val_loss: 4.7230\n","Epoch 75/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - loss: 4.7266 - val_loss: 4.6819\n","Epoch 76/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 4.6784 - val_loss: 4.6420\n","Epoch 77/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - loss: 4.6480 - val_loss: 4.6034\n","Epoch 78/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - loss: 4.6096 - val_loss: 4.5664\n","Epoch 79/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 4.5725 - val_loss: 4.5308\n","Epoch 80/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 4.5216 - val_loss: 4.4961\n","Epoch 81/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 4.5080 - val_loss: 4.4629\n","Epoch 82/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - loss: 4.4692 - val_loss: 4.4309\n","Epoch 83/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 4.4289 - val_loss: 4.3999\n","Epoch 84/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - loss: 4.4125 - val_loss: 4.3702\n","Epoch 85/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 4.3736 - val_loss: 4.3416\n","Epoch 86/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 4.3314 - val_loss: 4.3132\n","Epoch 87/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - loss: 4.3107 - val_loss: 4.2853\n","Epoch 88/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 4.2884 - val_loss: 4.2583\n","Epoch 89/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 4.2558 - val_loss: 4.2318\n","Epoch 90/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266ms/step - loss: 4.2424 - val_loss: 4.2063\n","Epoch 91/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 4.2202 - val_loss: 4.1819\n","Epoch 92/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 4.1923 - val_loss: 4.1587\n","Epoch 93/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 4.1583 - val_loss: 4.1359\n","Epoch 94/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 4.1395 - val_loss: 4.1138\n","Epoch 95/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 4.1161 - val_loss: 4.0922\n","Epoch 96/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - loss: 4.0931 - val_loss: 4.0709\n","Epoch 97/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - loss: 4.0836 - val_loss: 4.0506\n","Epoch 98/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step - loss: 4.0471 - val_loss: 4.0305\n","Epoch 99/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 4.0229 - val_loss: 4.0106\n","Epoch 100/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 4.0086 - val_loss: 3.9911\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n","              precision    recall  f1-score   support\n","\n","           0       0.23      0.46      0.31        13\n","           1       0.00      0.00      0.00        10\n","           2       0.25      0.11      0.15        18\n","\n","    accuracy                           0.20        41\n","   macro avg       0.16      0.19      0.15        41\n","weighted avg       0.18      0.20      0.17        41\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.32      1.00      0.48        13\n","           1       0.00      0.00      0.00        10\n","           2       0.00      0.00      0.00        18\n","\n","    accuracy                           0.32        41\n","   macro avg       0.11      0.33      0.16        41\n","weighted avg       0.10      0.32      0.15        41\n","\n"]}],"source":["df = pd.read_csv('df_89.csv')\n","train_3, test_3 = train_test_split(df, test_size=0.5, random_state=42)\n","features_train_3, features_test_3, y_train_3, y_test_3 = preprocess_data(train_3, test_3)\n","report_dict_3_0, report_dict_3_1 = evaluate_models(features_train_3, features_test_3, y_train_3, y_test_3)"]}],"metadata":{"colab":{"toc_visible":true,"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}